# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JDo7-mGs88W5LKItPoQa4PNLXRYtvD8e
"""

# !pip cache purge

# !pip install openai

# !pip install langchain

# !pip install streamlit

# !pip install langchain==0.0.148

# !pip install pydantic==1.10.6
# !pip install typing-inspect==0.8.0

# prompt: check python version

# !python --version

import streamlit as st
from langchain import OpenAI, LLMChain
from langchain.prompts import PromptTemplate
import os

#Set your OpenAi API key
os.environ["OPENAI_API_KEY"] = "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"

#Define your LangChain App
prompt_template = "You are a helpful assistant. Answer the question: {question}"
prompt = PromptTemplate(template=prompt_template, input_variables=["question"])

llm = OpenAI(model="gpt-3.5-turbo")
llm_chain = LLMChain(llm=llm, prompt=prompt)

st.title("LangChain App")
question = st.text_input("Ask a question:")

if question:
    response = llm_chain.run({"question": question})
    st.write(f"Response: {response}")

